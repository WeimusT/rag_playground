{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Test out GraphRag\n",
        "\n",
        "[Building a Graph RAG System: A Step-by-Step Approach](https://machinelearningmastery.com/building-graph-rag-system-step-by-step-approach/)\n",
        "\n",
        "## Why GraphRag\n",
        "\n",
        "The document retrieved by regular RAG systems can lack of dependenies and cause the answers generated by the LLM to be fragmented. The article [Building a Graph RAG System: A Step-by-Step Approach](https://machinelearningmastery.com/building-graph-rag-system-step-by-step-approach/) used a good example for the fragmented answer generated by regular RAG.\n",
        "\n",
        "    In a traditional RAG setup, the system might retrieve the following pieces of information:\n",
        "\n",
        "    Document 1: “James Watson and Francis Crick proposed the double-helix structure in 1953.”\n",
        "    Document 2: “Rosalind Franklin’s X-ray diffraction images were critical in identifying DNA’s helical structure.”\n",
        "    Document 3: “Maurice Wilkins shared Franklin’s images with Watson and Crick, which contributed to their discovery.”\n",
        "    The problem? Traditional RAG systems treat these documents as independent units. They don’t connect the dots effectively, leading to fragmented responses like: \n",
        "\n",
        "    “Watson and Crick proposed the structure, and Franklin’s work was important.”\n",
        "\n",
        "    This response lacks depth and misses key relationships between contributors. Enter Graph RAG! By organizing the retrieved data as a graph, Graph RAG represents each document or fact as a node, and the relationships between them as edges.\n",
        "\n",
        "    Here’s how Graph RAG would handle the same query:\n",
        "\n",
        "    Nodes: Represent facts (e.g., “Watson and Crick proposed the structure,” “Franklin contributed critical X-ray images”).\n",
        "    Edges: Represent relationships (e.g., “Franklin’s images → shared by Wilkins → influenced Watson and Crick”).\n",
        "    By reasoning across these interconnected nodes, Graph RAG can produce a complete and insightful response like:\n",
        "\n",
        "    “The discovery of DNA’s double-helix structure in 1953 was primarily led by James Watson and Francis Crick. However, this breakthrough heavily relied on Rosalind Franklin’s X-ray diffraction images, which were shared with them by Maurice Wilkins.”\n",
        "\n",
        "    This ability to combine information from multiple sources and answer broader, more complex questions is what makes Graph RAG so popular.\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initiate RAG Building Blocks\n",
        "\n",
        "Deploy Azure OpenAI Services, including an LLM and an embedding. Model deployed as an Azure endpoint on an [AI Foundary workspace](https://oai.azure.com/resource/overview?wsid=/subscriptions/d91792a2-c9bd-44bc-bcd8-fdddc7ceb1c5/resourceGroups/agentic_applications/providers/Microsoft.CognitiveServices/accounts/multi-agentic-applications&tid=565f1c8e-754e-473e-8352-ac5b86a38c93). Set and AZURE_OPENAI_API_KEY, AZURE_OPENAI_ENDPOINT and OPENAI_API_VERSION in .env file."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import dotenv\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "## Setup Environment\n",
        "sys.path.append(Path.cwd().parent) # Append project home to system path\n",
        "dotenv.load_dotenv(override=True) # Load .env"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1741959958103
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test Azure Connection\n",
        "import openai\n",
        "\n",
        "client = openai.AzureOpenAI(\n",
        "    api_version=\"2025-01-01-preview\",\n",
        ")\n",
        "\n",
        "# gpt-4o-mini only support chat completion. Use client.chat.completions.create instead of\n",
        "# client.completions.create\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[{\"role\": \"user\", \"content\": \"Test prompt\"}],\n",
        ")\n",
        "\n",
        "response"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "ChatCompletion(id='chatcmpl-BAzeI3ugv7hpA9c6q5mJol2FXxsZZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='It looks like you are testing the prompt functionality. How can I assist you today? If you have any questions or specific tasks in mind, feel free to let me know!', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None), content_filter_results={'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}})], created=1741959958, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier=None, system_fingerprint='fp_b705f0c291', usage=CompletionUsage(completion_tokens=35, prompt_tokens=9, total_tokens=44, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1741959959424
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup RAG Building Blocks\n",
        "\n",
        "* LLM\n",
        "* Embedding\n",
        "* Vector store"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "\n",
        "# Connect to chat model. \n",
        "# Here we use AzureChatOpenAI instead AzureOpenAI to connect to gpt-4o-mini\n",
        "llm = AzureChatOpenAI(azure_deployment=\"gpt-4o-mini\")\n",
        "\n",
        "# Connect to embedding\n",
        "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
        "\n",
        "# Instantiate vector store\n",
        "vector_store = InMemoryVectorStore(embeddings)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1741959960129
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Test azure connection\n",
        "llm.invoke(\"Tell me a joke\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "AIMessage(content=\"Why don't skeletons fight each other? \\n\\nThey don't have the guts!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 11, 'total_tokens': 26, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b705f0c291', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'low'}}}, id='run-6c1b0df1-a9a3-48ad-b2b6-7f98cf6d5c21-0', usage_metadata={'input_tokens': 11, 'output_tokens': 15, 'total_tokens': 26, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "gather": {
          "logged": 1741959960564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chunk Documents"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data\n",
        "import pandas as pd\n",
        "news = pd.read_csv(\"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/news_articles.csv\")[:50]\n",
        "news[:1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                    title                                 date  \\\n0  Chevron: Best Of Breed  2031-04-06T01:36:32.000000000+00:00   \n\n                                                text  \n0  JHVEPhoto Like many companies in the O&G secto...  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>date</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Chevron: Best Of Breed</td>\n      <td>2031-04-06T01:36:32.000000000+00:00</td>\n      <td>JHVEPhoto Like many companies in the O&amp;G secto...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1741959961097
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# Convert string to Langchain document\n",
        "news_documents = [Document(row[1]['text']) for row in news.iterrows()]\n",
        "news_documents[:1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "[Document(metadata={}, page_content='JHVEPhoto Like many companies in the O&G sector, the stock of Chevron (NYSE:CVX) has declined about 10% over the past 90-days despite the fact that Q2 consensus earnings estimates have risen sharply (~25%) during that same time frame. Over the years, Chevron has kept a very strong balance sheet. That allowed the...')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1741959961304
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splits text into chunks of 500 characters with a 100-character overlap to maintain context between chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "all_splits = text_splitter.split_documents(news_documents)\n",
        "all_splits[:1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "[Document(metadata={}, page_content='JHVEPhoto Like many companies in the O&G sector, the stock of Chevron (NYSE:CVX) has declined about 10% over the past 90-days despite the fact that Q2 consensus earnings estimates have risen sharply (~25%) during that same time frame. Over the years, Chevron has kept a very strong balance sheet. That allowed the...')]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1741959961473
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Knowledge Graph"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable\n",
        "\n",
        "from langchain_core.language_models.chat_models import BaseChatModel\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph\n",
        "\n",
        "class GraphRAGExtractor:\n",
        "   '''Extract triples from a graph.\n",
        "\n",
        "   Uses an LLM and a simple prompt + output parsing to extract paths (i.e. triples) and entity, relation descriptions from text.\n",
        "\n",
        "   Args:\n",
        "      llm (LLM):\n",
        "         The language model to use.\n",
        "      extract_prompt (Union[str, PromptTemplate]):\n",
        "         The prompt to use for extracting triples.\n",
        "      parse_fn (callable):\n",
        "         A function to parse the output of the language model.\n",
        "      num_workers (int):\n",
        "         The number of workers to use for parallel processing.\n",
        "      max_paths_per_chunk (int):\n",
        "         The maximum number of paths to extract per chunk.\n",
        "\n",
        "   '''\n",
        "   llm: BaseChatModel\n",
        "   extract_prompt: PromptTemplate\n",
        "   parse_fn: Callable"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1741959961617
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following is a simple example to show that the LLM generation is grounded to the retrieved triplets. Compared to the answer directly generated by the LLM, the RAG answer is more grounded to the knowledge stored in the Vector Store about Einstein. Besides, the generation does not seem to identify the knowledge clique, which is supposed to be a strength of Graph Rag. For example, the facts about Theory of Relativity is a theory in physics and it is developed in early 20th century is not reflected in the answer.\n",
        "\n",
        "\n",
        "```\n",
        "{\n",
        "    'query': 'Tell me about Albert Einstein', \n",
        "    'result': \"Albert Einstein was a theoretical physicist best known for developing the Theory of Relativity, which revolutionized our understanding of space, time, and gravity. He was born on March 14, 1879, in Ulm, Germany, and later became a Swiss citizen. Einstein's work laid the foundation for modern physics, particularly his famous equation E=mc², which describes the equivalence of mass and energy. Throughout his career, he received numerous awards and honors, including the Nobel Prize in Physics in 1921 for his explanation of the photoelectric effect. Einstein passed away on April 18, 1955, but his contributions to science continue to influence the field today.\"\n",
        "}\n",
        "```\n",
        "\n",
        "The consistency is another issue. The generation takes into account the second level relations about Einstein.\n",
        "\n",
        "```\n",
        "{\n",
        "    'query': 'Tell me about Albert Einstein', \n",
        "    'result': \"Albert Einstein was a renowned physicist who was born in 1879 and passed away in 1955. He is best known for developing the Theory of Relativity, which he worked on in the early 20th century. Einstein's contributions to science have had a profound impact on our understanding of physics and the universe. His work has influenced various fields and continues to be a subject of study and admiration today.\"}\n",
        "```\n",
        "\n",
        "Answers generated by LLM to the query 'Tell me about Altert Einstein'. This is done by calling `llm.invoke('Tell me about Albert Einstein')`.\n",
        "\n",
        "```\n",
        "AIMessage(content='Albert Einstein (1879-1955) was a theoretical physicist renowned for developing the theory of relativity, one of the two pillars of modern physics alongside quantum mechanics. His work revolutionized our understanding of space, time, and energy.\\n\\n### Early Life\\nBorn on March 14, 1879, in Ulm, Germany, Einstein showed an early interest in science and mathematics. He faced challenges in his schooling due to a nonconformist attitude and struggled with rigid educational systems. He later studied at the Polytechnic Institute in Zurich, where he graduated in 1900.\\n\\n### Career Highlights\\nEinstein initially worked as a patent examiner in Bern, Switzerland, where he developed many of his groundbreaking ideas during his free time. In 1905, often referred to as his \"miracle year,\" he published four pivotal papers:\\n1. **Special Theory of Relativity** – Introduced the famous equation E=mc², establishing the relationship between mass and energy.\\n2. **Photoelectric Effect** – Provided evidence for the quantization of light, which later contributed to the development of quantum theory; this work earned him the Nobel Prize in Physics in 1921.\\n3. **Brownian Motion** – Offered explanations for the random motion of particles suspended in fluids, providing empirical support for atomic theory.\\n4. **Mass-Energy Equivalence** – Established the foundational principles that would shape nuclear physics.\\n\\nIn 1915, Einstein completed his General Theory of Relativity, which expanded on his earlier work to include gravity as a curvature of spacetime rather than a force acting at a distance. This theory predicted phenomena like the bending of light around massive objects and was confirmed by observations during a solar eclipse in 1919.\\n\\n### Later Life and Legacy\\nEinstein immigrated to the United States in 1933, fleeing the rise of Nazism in Germany. He accepted a position at the Institute for Advanced Study in Princeton, New Jersey, where he continued his work until his death on April 18, 1955. Throughout his life, Einstein was involved in various social and political causes, advocating for pacifism, civil rights, and nuclear disarmament.\\n\\nEinstein\\'s contributions laid the groundwork for much of modern physics, and his work continues to influence numerous fields, including cosmology, quantum mechanics, and theoretical physics. His iconic status and the phrase \"Einstein\" have become synonymous with genius, and his legacy endures through both his scientific achievements and his humanitarian efforts.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 503, 'prompt_tokens': 12, 'total_tokens': 515, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_b705f0c291', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-bf0b8478-646f-4f87-8ce9-cc848312724d-0', usage_metadata={'input_tokens': 12, 'output_tokens': 503, 'total_tokens': 515, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n",
        "```\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs.networkx_graph import NetworkxEntityGraph, KnowledgeTriple\n",
        "from langchain.chains import RetrievalQA # According to ChatGPT, the GraphCyberQAChain requires a Neo4jGraph backend.\n",
        "\n",
        "# Initialize the graph\n",
        "graph = NetworkxEntityGraph()\n",
        "\n",
        "# Sample knowledge to extract relationships\n",
        "triplets = [\n",
        "    KnowledgeTriple(\"Albert Einstein\", \"discovered\", \"Theory of Relativity\"),\n",
        "    KnowledgeTriple(\"Albert Einstein\", \"born in\", \"1879\"),\n",
        "    KnowledgeTriple(\"Albert Einstein\", \"die at\", \"1955\"),\n",
        "    KnowledgeTriple(\"Isaac Newton\", \"formulated\", \"Laws of Motion\"),\n",
        "    KnowledgeTriple(\"Marie Curie\", \"pioneered\", \"Radioactivity\"),\n",
        "    KnowledgeTriple(\"Theory of Relativity\", \"is\", \"Theory in Physics\"),\n",
        "    KnowledgeTriple(\"Theory of Relativity\", \"develope time\", \"early 20th century\")\n",
        "]\n",
        "\n",
        "# Add entities and relationships to the graph\n",
        "for triplet in triplets:\n",
        "    graph.add_triple(triplet)\n",
        "\n",
        "# Convert graph to document\n",
        "documents = [Document(page_content=f\"{subj} {pred} {obj}\") for subj, pred, obj in triplets]\n",
        "\n",
        "# Add documents to vector store\n",
        "vector_store.add_documents(documents)\n",
        "\n",
        "# Create a retrieval-based QA chain\n",
        "retrieval_chain = RetrievalQA.from_chain_type(llm, retriever=vector_store.as_retriever())\n",
        "\n",
        "# Ask a question\n",
        "query = \"Tell me about Albert Einstein\"\n",
        "response = retrieval_chain.invoke(query)\n",
        "\n",
        "print(response)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{'query': 'Tell me about Albert Einstein', 'result': \"Albert Einstein was a renowned physicist who was born in 1879 and passed away in 1955. He is best known for developing the Theory of Relativity, which he worked on in the early 20th century. Einstein's contributions to science have had a profound impact on our understanding of physics and the universe. His work has influenced various fields and continues to be a subject of study and admiration today.\"}\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1741959963574
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"Tell me about Albert Einstein\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "AIMessage(content='Albert Einstein was a theoretical physicist born on March 14, 1879, in Ulm, Germany, and he passed away on April 18, 1955, in Princeton, New Jersey, USA. He is best known for developing the theory of relativity, particularly the mass-energy equivalence formula \\\\(E=mc^2\\\\), which has become one of the most famous equations in physics.\\n\\nEinstein\\'s early education was in Germany, where he struggled in some subjects but excelled in mathematics and physics. He earned a diploma from the Polytechnic Institute in Zurich, Switzerland, in 1900. After a brief period of working at the Swiss Patent Office, he published several groundbreaking papers in 1905, a year often referred to as his \"annus mirabilis\" or miracle year. These papers included his work on the photoelectric effect (for which he later received the Nobel Prize in Physics in 1921), Brownian motion, and special relativity.\\n\\nIn 1915, Einstein completed his general theory of relativity, which expanded the ideas of relativity to include acceleration and gravitation. This theory revolutionized our understanding of space, time, and gravity, replacing Newtonian mechanics in many areas of physics.\\n\\nEinstein\\'s contributions extended beyond theoretical physics. He was an outspoken advocate for civil rights, pacifism, and Zionism, and he was a prominent figure in various political and social movements throughout his life. He was also known for his philosophical reflections on science and its implications.\\n\\nIn 1933, with the rise of the Nazi regime, Einstein emigrated to the United States, where he accepted a position at the Institute for Advanced Study in Princeton. He continued to work on theoretical physics until his death, but he became increasingly concerned with the implications of nuclear weapons after the atomic bomb was developed during World War II.\\n\\nEinstein\\'s legacy extends far beyond his scientific contributions. He is regarded as a symbol of genius, creativity, and humanism, and his work continues to influence modern physics and science as a whole.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 414, 'prompt_tokens': 12, 'total_tokens': 426, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ded0d14823', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-8c237d77-abce-4018-8732-753e13193ccb-0', usage_metadata={'input_tokens': 12, 'output_tokens': 414, 'total_tokens': 426, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1741959967849
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph.get_entity_knowledge(entity=\"Albert Einstein\")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "['Albert Einstein discovered Theory of Relativity',\n 'Albert Einstein born in 1879',\n 'Albert Einstein die at 1955']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1741959968002
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enhance the retrieval using Leiden."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "from graspologic.partition import hierarchical_leiden"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'graspologic'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgraspologic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpartition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hierarchical_leiden\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graspologic'"
          ]
        }
      ],
      "execution_count": 55,
      "metadata": {
        "gather": {
          "logged": 1741959856514
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Require to install graphviz\n",
        "# import matplotlib.pyplot as plt\n",
        "# import networkx as nx\n",
        "\n",
        "# # Convert to NetworkX graph\n",
        "# graph.draw_graphviz()"
      ],
      "outputs": [],
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1741957991438
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install graspologic"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Collecting graspologic\n  Downloading graspologic-3.4.1-py3-none-any.whl.metadata (5.8 kB)\nCollecting POT<0.10,>=0.9 (from graspologic)\n  Downloading POT-0.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nCollecting anytree<3.0.0,>=2.12.1 (from graspologic)\n  Downloading anytree-2.12.1-py3-none-any.whl.metadata (8.1 kB)\nCollecting beartype<0.19.0,>=0.18.5 (from graspologic)\n  Downloading beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\nCollecting gensim<5.0.0,>=4.3.2 (from graspologic)\n  Downloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.2 kB)\nCollecting graspologic-native<2.0.0,>=1.2.1 (from graspologic)\n  Downloading graspologic_native-1.2.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.6 kB)\nCollecting hyppo<0.5.0,>=0.4.0 (from graspologic)\n  Downloading hyppo-0.4.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: joblib<2.0.0,>=1.4.2 in /anaconda/envs/rag/lib/python3.10/site-packages (from graspologic) (1.4.2)\nRequirement already satisfied: matplotlib<4.0.0,>=3.8.4 in /anaconda/envs/rag/lib/python3.10/site-packages (from graspologic) (3.9.2)\nRequirement already satisfied: networkx<4,>=3 in /anaconda/envs/rag/lib/python3.10/site-packages (from graspologic) (3.4.2)\nCollecting numpy<2.0.0,>=1.26.4 (from graspologic)\n  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\nRequirement already satisfied: scikit-learn<2.0.0,>=1.4.2 in /anaconda/envs/rag/lib/python3.10/site-packages (from graspologic) (1.5.2)\nCollecting scipy==1.12.0 (from graspologic)\n  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\nCollecting seaborn<0.14.0,>=0.13.2 (from graspologic)\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting statsmodels<0.15.0,>=0.14.2 (from graspologic)\n  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.2 kB)\nRequirement already satisfied: typing-extensions<5.0.0,>=4.4.0 in /anaconda/envs/rag/lib/python3.10/site-packages (from graspologic) (4.12.2)\nCollecting umap-learn<0.6.0,>=0.5.6 (from graspologic)\n  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: six in /anaconda/envs/rag/lib/python3.10/site-packages (from anytree<3.0.0,>=2.12.1->graspologic) (1.16.0)\nCollecting smart-open>=1.8.1 (from gensim<5.0.0,>=4.3.2->graspologic)\n  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\nCollecting numba>=0.46 (from hyppo<0.5.0,>=0.4.0->graspologic)\n  Downloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\nCollecting autograd>=1.3 (from hyppo<0.5.0,>=0.4.0->graspologic)\n  Downloading autograd-1.7.0-py3-none-any.whl.metadata (7.5 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (24.1)\nRequirement already satisfied: pillow>=8 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (10.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (3.1.4)\nRequirement already satisfied: python-dateutil>=2.7 in /anaconda/envs/rag/lib/python3.10/site-packages (from matplotlib<4.0.0,>=3.8.4->graspologic) (2.9.0)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /anaconda/envs/rag/lib/python3.10/site-packages (from scikit-learn<2.0.0,>=1.4.2->graspologic) (3.5.0)\nRequirement already satisfied: pandas>=1.2 in /anaconda/envs/rag/lib/python3.10/site-packages (from seaborn<0.14.0,>=0.13.2->graspologic) (2.2.3)\nCollecting patsy>=0.5.6 (from statsmodels<0.15.0,>=0.14.2->graspologic)\n  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\nCollecting pynndescent>=0.5 (from umap-learn<0.6.0,>=0.5.6->graspologic)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nRequirement already satisfied: tqdm in /anaconda/envs/rag/lib/python3.10/site-packages (from umap-learn<0.6.0,>=0.5.6->graspologic) (4.66.5)\nCollecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.46->hyppo<0.5.0,>=0.4.0->graspologic)\n  Downloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: pytz>=2020.1 in /anaconda/envs/rag/lib/python3.10/site-packages (from pandas>=1.2->seaborn<0.14.0,>=0.13.2->graspologic) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /anaconda/envs/rag/lib/python3.10/site-packages (from pandas>=1.2->seaborn<0.14.0,>=0.13.2->graspologic) (2024.1)\nRequirement already satisfied: wrapt in /anaconda/envs/rag/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim<5.0.0,>=4.3.2->graspologic) (1.16.0)\nDownloading graspologic-3.4.1-py3-none-any.whl (5.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading anytree-2.12.1-py3-none-any.whl (44 kB)\nDownloading beartype-0.18.5-py3-none-any.whl (917 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading gensim-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading graspologic_native-1.2.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (365 kB)\nDownloading hyppo-0.4.0-py3-none-any.whl (146 kB)\nDownloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading POT-0.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (865 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.6/865.6 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\nDownloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\nDownloading autograd-1.7.0-py3-none-any.whl (52 kB)\nDownloading numba-0.61.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\nDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\nDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\nDownloading llvmlite-0.44.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: smart-open, numpy, llvmlite, graspologic-native, beartype, anytree, scipy, patsy, numba, autograd, statsmodels, POT, gensim, seaborn, pynndescent, hyppo, umap-learn, graspologic\n  Attempting uninstall: numpy\n    Found existing installation: numpy 2.0.2\n    Uninstalling numpy-2.0.2:\n      Successfully uninstalled numpy-2.0.2\n  Attempting uninstall: scipy\n    Found existing installation: scipy 1.14.1\n    Uninstalling scipy-1.14.1:\n      Successfully uninstalled scipy-1.14.1\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.18.0 requires keras>=3.5.0, which is not installed.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed POT-0.9.5 anytree-2.12.1 autograd-1.7.0 beartype-0.18.5 gensim-4.3.3 graspologic-3.4.1 graspologic-native-1.2.3 hyppo-0.4.0 llvmlite-0.44.0 numba-0.61.0 numpy-1.26.4 patsy-1.0.1 pynndescent-0.5.13 scipy-1.12.0 seaborn-0.13.2 smart-open-7.1.0 statsmodels-0.14.4 umap-learn-0.5.7\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 56,
      "metadata": {
        "gather": {
          "logged": 1741959905149
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras>=3.5.0"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Note: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 57,
      "metadata": {
        "gather": {
          "logged": 1741959942735
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "rag"
    },
    "kernelspec": {
      "name": "rag",
      "language": "python",
      "display_name": "rag"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}